{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8052995,"sourceType":"datasetVersion","datasetId":4749278},{"sourceId":8204914,"sourceType":"datasetVersion","datasetId":4861131},{"sourceId":8209953,"sourceType":"datasetVersion","datasetId":4863826}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# !pip install -U torchdata\n# !pip install -U spacy\n# !python -m spacy download en_core_web_lg\n# !python -m spacy download de_core_news_lg\n# !pip install portalocker\n! pip install accelerate -U\n! pip install evaluate\n! pip install sentence-transformers\n! pip install SentencePiece\n! pip install bert_score\n! pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:39:07.713441Z","iopub.execute_input":"2024-04-25T09:39:07.714256Z","iopub.status.idle":"2024-04-25T09:40:31.27906Z","shell.execute_reply.started":"2024-04-25T09:39:07.714225Z","shell.execute_reply":"2024-04-25T09:40:31.277794Z"}}},{"cell_type":"code","source":"#  import T5\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nimport numpy as np\nimport os\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DebertaTokenizer,\n    DebertaForSequenceClassification,\n    AutoConfig,\n)\n\nimport logging\nimport evaluate\nfrom evaluate import load\nfrom datasets import load_dataset\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import T5Tokenizer,T5ForConditionalGeneration\n\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu\n\nimport matplotlib.pyplot as plt\n\nfrom  transformers  import  AutoTokenizer, AutoModelWithLMHead\n\nimport csv\nfrom torch.utils.data import DataLoader, Dataset\nimport json\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\nimport numpy as np\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndevice=\"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'Using GPU: {torch.cuda.get_device_name()}')\nelse:\n    device = torch.device(\"cpu\")\n    print('Using CPU')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:31.281268Z","iopub.execute_input":"2024-04-25T09:40:31.281605Z","iopub.status.idle":"2024-04-25T09:40:49.898575Z","shell.execute_reply.started":"2024-04-25T09:40:31.281573Z","shell.execute_reply":"2024-04-25T09:40:49.897499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH=\"/kaggle/input/webis-clickbait-22/\"\nOUTPATH=\"/kaggle/working/\"\n# PATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\\"\n# OUTPATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\output\\\\\"\nBATCH=8\nT5_model=\"/kaggle/input/nlpprojt5/T5_overall\"#phrase\nT5_model=\"/kaggle/input/nlpprojt5/T5_overall_passage\"\nT5_model=\"/kaggle/input/nlpprojt5/T5_overall_multi\"\nsep='[SEP]'","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:49.900013Z","iopub.execute_input":"2024-04-25T09:40:49.900665Z","iopub.status.idle":"2024-04-25T09:40:49.90593Z","shell.execute_reply.started":"2024-04-25T09:40:49.900634Z","shell.execute_reply":"2024-04-25T09:40:49.904909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag=\"phrase\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:49.908644Z","iopub.execute_input":"2024-04-25T09:40:49.909398Z","iopub.status.idle":"2024-04-25T09:40:50.228733Z","shell.execute_reply.started":"2024-04-25T09:40:49.909366Z","shell.execute_reply":"2024-04-25T09:40:50.227664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_escape(l):\n    return l.replace(\"\\n\",\". \")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:50.230332Z","iopub.execute_input":"2024-04-25T09:40:50.230649Z","iopub.status.idle":"2024-04-25T09:40:50.2394Z","shell.execute_reply.started":"2024-04-25T09:40:50.230623Z","shell.execute_reply":"2024-04-25T09:40:50.238513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(x):\n    return \" \".join(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:50.240449Z","iopub.execute_input":"2024-04-25T09:40:50.240726Z","iopub.status.idle":"2024-04-25T09:40:50.249857Z","shell.execute_reply.started":"2024-04-25T09:40:50.240703Z","shell.execute_reply":"2024-04-25T09:40:50.248938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_json(\"/kaggle/input/retriever/final_data_train.json\")\nval_data=pd.read_json(\"/kaggle/input/retriever/final_data_validation.json\")\ntest_data=pd.read_json(\"/kaggle/input/retriever/final_data_test.json\")\n\ntrain_data = train_data.replace({None: ''})\nval_data = val_data.replace({None: ''})\ntest_data = test_data.replace({None: ''})\n\ntrain_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/train.jsonl\",lines=True)\nval_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/validation.jsonl\",lines=True)\ntest_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/test.jsonl\",lines=True)\n\ntrain_labels=train_real['spoiler'].apply(get_label)\nval_labels=val_real['spoiler'].apply(get_label)\ntest_labels=test_real['spoiler'].apply(get_label)\n\ntrain_tags=train_real['tags'].apply(get_label)\nval_tags=val_real['tags'].apply(get_label)\ntest_tags=test_real['tags'].apply(get_label)\n# train_type=train_real['spoiler']\ntrain_data['exctractedParagraph']=train_data['exctractedParagraph'].apply(remove_escape)\nval_data['exctractedParagraph']=val_data['exctractedParagraph'].apply(remove_escape)\ntest_data['exctractedParagraph']=test_data['exctractedParagraph'].apply(remove_escape)\n\ntrain_data['context']=train_data['targetTitle'] + ' ' + train_data['targetDescription']+\" \"+train_data['exctractedParagraph']\nval_data['context']=val_data['targetTitle'] + ' ' + val_data['targetDescription']+\" \"+val_data['exctractedParagraph']\ntest_data['context']=test_data['targetTitle'] + ' ' + test_data['targetDescription']+\" \"+test_data['exctractedParagraph']\n\ntrain_data['question']=train_data['postText']+\"?\"\nval_data['question']=val_data['postText']+'?'\ntest_data['question']=test_data['postText']+\"?\"\n\ntrain_data['spoiler']=train_labels\nval_data['spoiler']=val_labels\ntest_data['spoiler']=test_labels\n\ntrain_data['tags']=train_tags\nval_data['tags']=val_tags\ntest_data['tags']=test_tags\n\ntrain_data=train_data[train_data['tags']==tag]\nval_data=val_data[val_data['tags']==tag]\ntest_data=test_data[test_data['tags']==tag]\n\ntrain_data=train_data[['question','context','spoiler']]\n\nval_data=val_data[['question','context','spoiler']]\ntest_data=test_data[['question','context','spoiler']]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:42:58.202136Z","iopub.execute_input":"2024-04-25T09:42:58.202497Z","iopub.status.idle":"2024-04-25T09:42:59.026381Z","shell.execute_reply.started":"2024-04-25T09:42:58.202469Z","shell.execute_reply":"2024-04-25T09:42:59.025429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:41.72503Z","iopub.execute_input":"2024-04-23T22:10:41.725308Z","iopub.status.idle":"2024-04-23T22:10:41.739887Z","shell.execute_reply.started":"2024-04-23T22:10:41.725283Z","shell.execute_reply":"2024-04-23T22:10:41.738879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preproc(data):\n    q=[]\n    c=[]\n    a=[]\n    # print(len(data))\n    # print(len(data['question']))\n    # print(len(data['context']))\n    # print(len(data['spoiler']))\n    for i in range(len(data['question'])):\n        q.append(data['question'][i])\n        c.append(data['context'][i])\n        if c[i]==None:\n            c[i]=\"\"\n        a.append(str(data['spoiler'][i]))\n    model_inputs=tokenizer(q,c,text_target=a,return_tensors='pt',padding=True,truncation=True,max_length=512)\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:40:54.344649Z","iopub.status.idle":"2024-04-25T09:40:54.345067Z","shell.execute_reply.started":"2024-04-25T09:40:54.344866Z","shell.execute_reply":"2024-04-25T09:40:54.344895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data=Dataset.from_pandas(train_df)\ntokenized_train=train_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_val=val_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_test=test_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_train,tokenized_val,tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:42.678068Z","iopub.execute_input":"2024-04-23T22:10:42.678364Z","iopub.status.idle":"2024-04-23T22:10:45.366542Z","shell.execute_reply.started":"2024-04-23T22:10:42.678328Z","shell.execute_reply":"2024-04-23T22:10:45.365692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:45.367715Z","iopub.execute_input":"2024-04-23T22:10:45.367996Z","iopub.status.idle":"2024-04-23T22:10:45.37277Z","shell.execute_reply.started":"2024-04-23T22:10:45.367973Z","shell.execute_reply":"2024-04-23T22:10:45.371838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(T5_model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:47.851416Z","iopub.execute_input":"2024-04-23T22:10:47.852313Z","iopub.status.idle":"2024-04-23T22:10:48.96889Z","shell.execute_reply.started":"2024-04-23T22:10:47.852273Z","shell.execute_reply":"2024-04-23T22:10:48.967965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bertscore = load(\"bertscore\")\nmeteor = evaluate.load(\"meteor\")\nbleu = evaluate.load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:48.969925Z","iopub.execute_input":"2024-04-23T22:10:48.970207Z","iopub.status.idle":"2024-04-23T22:10:51.200397Z","shell.execute_reply.started":"2024-04-23T22:10:48.970183Z","shell.execute_reply":"2024-04-23T22:10:51.199678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    pred, ref = postprocess_text(decoded_preds, decoded_labels)\n\n    # cal bleu, meteor and bert\n    bleu_score = bleu.compute(predictions=pred, references=ref)\n#     bleu1 = corpus_bleu(ref,pred,weights=(1,0,0,0))\n#     bleu2 = corpus_bleu(ref,pred,weights=(0.5,0.5,0))\n#     bleu3 = corpus_bleu(ref,pred,weights=(0.33,0.33,0.33,0)\n#     bleu4 = corpus_bleu(ref,pred,weights=(0.25,0.25,0.25,0.25))\n\n    print(bleu_score)\n    meteor_score = meteor.compute(predictions=pred, references=ref)\n    bertscore_score = bertscore.compute(predictions=pred, references=ref, lang=\"en\")\n\n    #  dict\n    return {\"blue\":bleu_score[\"bleu\"],\n            \"precisions_1\":bleu_score[\"precisions\"][0],\n            \"precisions_2\":bleu_score[\"precisions\"][1],\n            \"precisions_3\":bleu_score[\"precisions\"][2],\n            \"precisions_4\":bleu_score[\"precisions\"][3],\n            \"bp\":bleu_score[\"brevity_penalty\"],\n            \"meteor\": meteor_score[\"meteor\"], \n            \"bertscore_f1\": np.average(bertscore_score[\"f1\"]), \n            \"bertscore_p\": np.average(bertscore_score[\"precision\"]), \n            \"bertscore_r\": np.average(bertscore_score[\"recall\"])}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.201527Z","iopub.execute_input":"2024-04-23T22:10:51.20189Z","iopub.status.idle":"2024-04-23T22:10:51.211692Z","shell.execute_reply.started":"2024-04-23T22:10:51.201864Z","shell.execute_reply":"2024-04-23T22:10:51.210706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./T5\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=BATCH,\n    per_device_eval_batch_size=BATCH,\n    weight_decay=0.01,\n    save_total_limit=5,\n    num_train_epochs=12,\n    predict_with_generate=True,\n    save_strategy=\"epoch\",\n    fp16=True,\n#     report_to=\"wandb\",\n#     logging_dir='./lolololol'\n\n    # push_to_hub=True\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"bleu\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.212888Z","iopub.execute_input":"2024-04-23T22:10:51.213148Z","iopub.status.idle":"2024-04-23T22:10:51.268423Z","shell.execute_reply.started":"2024-04-23T22:10:51.213126Z","shell.execute_reply":"2024-04-23T22:10:51.267441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_bleu(bp,precisions):\n    weights_1 = np.array([1,0,0,0])\n    weights_2 = np.array([0.5,0.5,0,0])\n    weights_3 = np.array([0.33,0.33,0.33,0])\n    weights_4 = np.array([0.25,0.25,0.25,0.25])\n    logp = np.log(precisions)\n        \n    res1 = bp*np.exp(np.dot(logp,weights_1))\n    res2 = bp*np.exp(np.dot(logp,weights_2))\n    res3 = bp*np.exp(np.dot(logp,weights_3))\n    res4 = bp*np.exp(np.dot(logp,weights_4))\n    \n    return [res1,res2,res3,res4]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.269763Z","iopub.execute_input":"2024-04-23T22:10:51.27038Z","iopub.status.idle":"2024-04-23T22:10:51.278549Z","shell.execute_reply.started":"2024-04-23T22:10:51.270346Z","shell.execute_reply":"2024-04-23T22:10:51.277623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results=trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.279635Z","iopub.execute_input":"2024-04-23T22:10:51.279924Z","iopub.status.idle":"2024-04-23T22:10:51.288001Z","shell.execute_reply.started":"2024-04-23T22:10:51.279902Z","shell.execute_reply":"2024-04-23T22:10:51.28717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.289099Z","iopub.execute_input":"2024-04-23T22:10:51.289378Z","iopub.status.idle":"2024-04-23T22:10:51.297501Z","shell.execute_reply.started":"2024-04-23T22:10:51.289357Z","shell.execute_reply":"2024-04-23T22:10:51.296855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:10:51.632722Z","iopub.execute_input":"2024-04-23T22:10:51.632998Z","iopub.status.idle":"2024-04-23T22:11:41.563569Z","shell.execute_reply.started":"2024-04-23T22:10:51.632974Z","shell.execute_reply":"2024-04-23T22:11:41.562683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T22:11:41.564984Z","iopub.execute_input":"2024-04-23T22:11:41.565456Z","iopub.status.idle":"2024-04-23T22:11:41.576659Z","shell.execute_reply.started":"2024-04-23T22:11:41.565422Z","shell.execute_reply":"2024-04-23T22:11:41.575682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}