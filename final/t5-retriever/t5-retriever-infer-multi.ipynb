{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8052995,"sourceType":"datasetVersion","datasetId":4749278},{"sourceId":8204914,"sourceType":"datasetVersion","datasetId":4861131},{"sourceId":8209953,"sourceType":"datasetVersion","datasetId":4863826},{"sourceId":8229562,"sourceType":"datasetVersion","datasetId":4880165}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install accelerate -U \n! pip install evaluate \n! pip install sentence-transformers \n! pip install SentencePiece \n! pip install bert_score \n! pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:42.154896Z","iopub.execute_input":"2024-04-25T17:47:42.155170Z","iopub.status.idle":"2024-04-25T17:48:58.306570Z","shell.execute_reply.started":"2024-04-25T17:47:42.155146Z","shell.execute_reply":"2024-04-25T17:48:58.305564Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting evaluate\n  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Using cached responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nUsing cached evaluate-0.4.1-py3-none-any.whl (84 kB)\nUsing cached responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting bert_score\n  Using cached bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.4)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.39.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.22.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#  import T5\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nimport numpy as np\nimport os\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DebertaTokenizer,\n    DebertaForSequenceClassification,\n    AutoConfig,\n)\n\nimport logging\nimport evaluate\nfrom evaluate import load\nfrom datasets import load_dataset\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import T5Tokenizer,T5ForConditionalGeneration\n\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu\n\nimport matplotlib.pyplot as plt\n\nfrom  transformers  import  AutoTokenizer, AutoModelWithLMHead\n\nimport csv\nfrom torch.utils.data import DataLoader, Dataset\nimport json\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\nimport numpy as np\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndevice=\"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'Using GPU: {torch.cuda.get_device_name()}')\nelse:\n    device = torch.device(\"cpu\")\n    print('Using CPU')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:58.311562Z","iopub.execute_input":"2024-04-25T17:48:58.311803Z","iopub.status.idle":"2024-04-25T17:49:06.146295Z","shell.execute_reply.started":"2024-04-25T17:48:58.311776Z","shell.execute_reply":"2024-04-25T17:49:06.145343Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-25 17:49:03.408726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-25 17:49:03.408784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-25 17:49:03.410496: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH=\"/kaggle/input/webis-clickbait-22/\"\nOUTPATH=\"/kaggle/working/\"\n# PATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\\"\n# OUTPATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\output\\\\\"\nBATCH=8\n# T5_model=\"/kaggle/input/nlpprojt5/T5_overall\"#phrase\n# T5_model=\"/kaggle/input/t5-retriver/retriever_passage/T5_overall_passage\"\nT5_model=\"/kaggle/input/t5-retriver/retriever_multi/T5_overall_passage\"\nsep='[SEP]'","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.147389Z","iopub.execute_input":"2024-04-25T17:49:06.147978Z","iopub.status.idle":"2024-04-25T17:49:06.152920Z","shell.execute_reply.started":"2024-04-25T17:49:06.147950Z","shell.execute_reply":"2024-04-25T17:49:06.151888Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tag=\"multi\"","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.156396Z","iopub.execute_input":"2024-04-25T17:49:06.157080Z","iopub.status.idle":"2024-04-25T17:49:06.204247Z","shell.execute_reply.started":"2024-04-25T17:49:06.157033Z","shell.execute_reply":"2024-04-25T17:49:06.203288Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.205462Z","iopub.execute_input":"2024-04-25T17:49:06.205779Z","iopub.status.idle":"2024-04-25T17:49:06.498662Z","shell.execute_reply.started":"2024-04-25T17:49:06.205751Z","shell.execute_reply":"2024-04-25T17:49:06.497668Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_escape(l):\n    return l.replace(\"\\n\",\". \")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.500039Z","iopub.execute_input":"2024-04-25T17:49:06.500427Z","iopub.status.idle":"2024-04-25T17:49:06.508115Z","shell.execute_reply.started":"2024-04-25T17:49:06.500390Z","shell.execute_reply":"2024-04-25T17:49:06.507208Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_label(x):\n    return \" \".join(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.509088Z","iopub.execute_input":"2024-04-25T17:49:06.509335Z","iopub.status.idle":"2024-04-25T17:49:06.518031Z","shell.execute_reply.started":"2024-04-25T17:49:06.509312Z","shell.execute_reply":"2024-04-25T17:49:06.517137Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_json(\"/kaggle/input/retriever/final_data_train.json\")\nval_data=pd.read_json(\"/kaggle/input/retriever/final_data_validation.json\")\ntest_data=pd.read_json(\"/kaggle/input/retriever/final_data_test.json\")\n\ntrain_data = train_data.replace({None: ''})\nval_data = val_data.replace({None: ''})\ntest_data = test_data.replace({None: ''})\n\ntrain_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/train.jsonl\",lines=True)\nval_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/validation.jsonl\",lines=True)\ntest_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/test.jsonl\",lines=True)\n\ntrain_labels=train_real['spoiler'].apply(get_label)\nval_labels=val_real['spoiler'].apply(get_label)\ntest_labels=test_real['spoiler'].apply(get_label)\n\ntrain_tags=train_real['tags'].apply(get_label)\nval_tags=val_real['tags'].apply(get_label)\ntest_tags=test_real['tags'].apply(get_label)\n# train_type=train_real['spoiler']\ntrain_data['exctractedParagraph']=train_data['exctractedParagraph'].apply(remove_escape)\nval_data['exctractedParagraph']=val_data['exctractedParagraph'].apply(remove_escape)\ntest_data['exctractedParagraph']=test_data['exctractedParagraph'].apply(remove_escape)\n\ntrain_data['context']=train_data['targetTitle'] + ' ' + train_data['targetDescription']+\" \"+train_data['exctractedParagraph']\nval_data['context']=val_data['targetTitle'] + ' ' + val_data['targetDescription']+\" \"+val_data['exctractedParagraph']\ntest_data['context']=test_data['targetTitle'] + ' ' + test_data['targetDescription']+\" \"+test_data['exctractedParagraph']\n\ntrain_data['question']=train_data['postText']+\"?\"\nval_data['question']=val_data['postText']+'?'\ntest_data['question']=test_data['postText']+\"?\"\n\ntrain_data['spoiler']=train_labels\nval_data['spoiler']=val_labels\ntest_data['spoiler']=test_labels\n\ntrain_data['tags']=train_tags\nval_data['tags']=val_tags\ntest_data['tags']=test_tags\n\ntrain_data=train_data[train_data['tags']==tag]\nval_data=val_data[val_data['tags']==tag]\ntest_data=test_data[test_data['tags']==tag]\n\ntrain_data=train_data[['question','context','spoiler']]\n\nval_data=val_data[['question','context','spoiler']]\ntest_data=test_data[['question','context','spoiler']]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.519231Z","iopub.execute_input":"2024-04-25T17:49:06.519519Z","iopub.status.idle":"2024-04-25T17:49:07.832790Z","shell.execute_reply.started":"2024-04-25T17:49:06.519479Z","shell.execute_reply":"2024-04-25T17:49:07.831899Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:07.834128Z","iopub.execute_input":"2024-04-25T17:49:07.834509Z","iopub.status.idle":"2024-04-25T17:49:07.853299Z","shell.execute_reply.started":"2024-04-25T17:49:07.834473Z","shell.execute_reply":"2024-04-25T17:49:07.852302Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                               question  \\\n3     Passion is overrated — 7 work habits you need ...   \n9     Hot Sauce Taste Test: Find out which we named ...   \n20    Human remains found in the search for missing ...   \n43    Six lessons from the godfather of California c...   \n44    The Fastest Growing Economy in the World! Numb...   \n...                                                 ...   \n3188  Medical marijuana bills advance in these South...   \n3190  This Guy Cheated On 'The Price Is Right' And F...   \n3191                  7 small changes to try this week?   \n3192  11 of the weirdest foods you should try, accor...   \n3197  5 popular myths about visible signs of aging t...   \n\n                                                context  \\\n3     ‘Follow your passion’ is wrong, here are 7 hab...   \n9     Taste test: 29 hot sauce bottles, ranked From ...   \n20    Human Remains Found In Search For Missing Teen...   \n43    6 Lessons From The Pioneer Of Modern Californi...   \n44    The Fastest Growing Economies in the World (No...   \n...                                                 ...   \n3188  Medical Marijuana Bills Advance In Georgia, Ke...   \n3190  This Guy Figured Out ‘The Price Is Right’ Algo...   \n3191  7 Small Changes To Try This Week  \"One of the ...   \n3192  11 of the weirdest foods you should try, accor...   \n3197  5 popular myths about visible signs of aging t...   \n\n                                                spoiler  \n3     Purpose connects us to something bigger and in...  \n9     Sriracha Hot Chili Sauce Frank's RedHot Origin...  \n20             Southampton County Anjelica 'AJ' Hadsell  \n43    Daniel Patterson 1) Eat your veggies. 2) Enjoy...  \n44    1. India 2. Bangladesh 3. China 4. Indonesia 5...  \n...                                                 ...  \n3188                                   Georgia Kentucky  \n3190  Terry Kniess All of the prices in the show hav...  \n3191  Relax with rain sounds. Put pressure on period...  \n3192  Cream cheese with a bit of strawberry jam on a...  \n3197  1. Anti-wrinkle creams will erase the fine lin...  \n\n[559 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>spoiler</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>Passion is overrated — 7 work habits you need ...</td>\n      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n      <td>Purpose connects us to something bigger and in...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hot Sauce Taste Test: Find out which we named ...</td>\n      <td>Taste test: 29 hot sauce bottles, ranked From ...</td>\n      <td>Sriracha Hot Chili Sauce Frank's RedHot Origin...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Human remains found in the search for missing ...</td>\n      <td>Human Remains Found In Search For Missing Teen...</td>\n      <td>Southampton County Anjelica 'AJ' Hadsell</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Six lessons from the godfather of California c...</td>\n      <td>6 Lessons From The Pioneer Of Modern Californi...</td>\n      <td>Daniel Patterson 1) Eat your veggies. 2) Enjoy...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>The Fastest Growing Economy in the World! Numb...</td>\n      <td>The Fastest Growing Economies in the World (No...</td>\n      <td>1. India 2. Bangladesh 3. China 4. Indonesia 5...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3188</th>\n      <td>Medical marijuana bills advance in these South...</td>\n      <td>Medical Marijuana Bills Advance In Georgia, Ke...</td>\n      <td>Georgia Kentucky</td>\n    </tr>\n    <tr>\n      <th>3190</th>\n      <td>This Guy Cheated On 'The Price Is Right' And F...</td>\n      <td>This Guy Figured Out ‘The Price Is Right’ Algo...</td>\n      <td>Terry Kniess All of the prices in the show hav...</td>\n    </tr>\n    <tr>\n      <th>3191</th>\n      <td>7 small changes to try this week?</td>\n      <td>7 Small Changes To Try This Week  \"One of the ...</td>\n      <td>Relax with rain sounds. Put pressure on period...</td>\n    </tr>\n    <tr>\n      <th>3192</th>\n      <td>11 of the weirdest foods you should try, accor...</td>\n      <td>11 of the weirdest foods you should try, accor...</td>\n      <td>Cream cheese with a bit of strawberry jam on a...</td>\n    </tr>\n    <tr>\n      <th>3197</th>\n      <td>5 popular myths about visible signs of aging t...</td>\n      <td>5 popular myths about visible signs of aging t...</td>\n      <td>1. Anti-wrinkle creams will erase the fine lin...</td>\n    </tr>\n  </tbody>\n</table>\n<p>559 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def preproc(data):\n    q=[]\n    c=[]\n    a=[]\n    # print(len(data))\n    # print(len(data['question']))\n    # print(len(data['context']))\n    # print(len(data['spoiler']))\n    for i in range(len(data['question'])):\n        q.append(data['question'][i])\n        c.append(data['context'][i])\n        if c[i]==None:\n            c[i]=\"\"\n        a.append(str(data['spoiler'][i]))\n    model_inputs=tokenizer(q,c,text_target=a,return_tensors='pt',padding=True,truncation=True,max_length=512)\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:07.854399Z","iopub.execute_input":"2024-04-25T17:49:07.854709Z","iopub.status.idle":"2024-04-25T17:49:07.861804Z","shell.execute_reply.started":"2024-04-25T17:49:07.854683Z","shell.execute_reply":"2024-04-25T17:49:07.860809Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(T5_model)\nmodel = AutoModelWithLMHead.from_pretrained(T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:07.863110Z","iopub.execute_input":"2024-04-25T17:49:07.863421Z","iopub.status.idle":"2024-04-25T17:49:15.655312Z","shell.execute_reply.started":"2024-04-25T17:49:07.863394Z","shell.execute_reply":"2024-04-25T17:49:15.654348Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\n\n### convert to Huggingface dataset\ntrain_dataset = Dataset(pa.Table.from_pandas(train_data)).remove_columns([\"__index_level_0__\"])\n\nval_dataset = Dataset(pa.Table.from_pandas(val_data)).remove_columns([\"__index_level_0__\"])\ntest_dataset = Dataset(pa.Table.from_pandas(test_data)).remove_columns([\"__index_level_0__\"])\ntrain_dataset,val_dataset,test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:15.656991Z","iopub.execute_input":"2024-04-25T17:49:15.657352Z","iopub.status.idle":"2024-04-25T17:49:15.760662Z","shell.execute_reply.started":"2024-04-25T17:49:15.657321Z","shell.execute_reply":"2024-04-25T17:49:15.759260Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 559\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 143\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 174\n }))"},"metadata":{}}]},{"cell_type":"code","source":"# train_data=Dataset.from_pandas(train_df)\ntokenized_train=train_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_val=val_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_test=test_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_train,tokenized_val,tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:15.762113Z","iopub.execute_input":"2024-04-25T17:49:15.762474Z","iopub.status.idle":"2024-04-25T17:49:17.456508Z","shell.execute_reply.started":"2024-04-25T17:49:15.762438Z","shell.execute_reply":"2024-04-25T17:49:17.455442Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/559 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38aa496d1dcc489a84819337fedde322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/143 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c712afb62c004e168bd866dc40895f0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/174 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26b4835ed1a345c9aed2a9c6329326d6"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 559\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 143\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 174\n }))"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:17.461240Z","iopub.execute_input":"2024-04-25T17:49:17.461626Z","iopub.status.idle":"2024-04-25T17:49:17.467179Z","shell.execute_reply.started":"2024-04-25T17:49:17.461592Z","shell.execute_reply":"2024-04-25T17:49:17.465982Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(T5_model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:17.468360Z","iopub.execute_input":"2024-04-25T17:49:17.468697Z","iopub.status.idle":"2024-04-25T17:49:18.722924Z","shell.execute_reply.started":"2024-04-25T17:49:17.468667Z","shell.execute_reply":"2024-04-25T17:49:18.721986Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bertscore = load(\"bertscore\")\nmeteor = evaluate.load(\"meteor\")\nbleu = evaluate.load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:18.724126Z","iopub.execute_input":"2024-04-25T17:49:18.724421Z","iopub.status.idle":"2024-04-25T17:49:21.796951Z","shell.execute_reply.started":"2024-04-25T17:49:18.724395Z","shell.execute_reply":"2024-04-25T17:49:21.795972Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c781bda58934ee9b6df5436d1308afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72afb63d02a4c139a20be52c5aa07e5"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef8847f9333e4d7b96234eb372558582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c34b1a6de304164b6ff527d65e1d35a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"210a589df0bf4e20a410209fdfc6f0f0"}},"metadata":{}}]},{"cell_type":"code","source":"\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    pred, ref = postprocess_text(decoded_preds, decoded_labels)\n\n    # cal bleu, meteor and bert\n    bleu_score = bleu.compute(predictions=pred, references=ref)\n#     bleu1 = corpus_bleu(ref,pred,weights=(1,0,0,0))\n#     bleu2 = corpus_bleu(ref,pred,weights=(0.5,0.5,0))\n#     bleu3 = corpus_bleu(ref,pred,weights=(0.33,0.33,0.33,0)\n#     bleu4 = corpus_bleu(ref,pred,weights=(0.25,0.25,0.25,0.25))\n\n    print(bleu_score)\n    meteor_score = meteor.compute(predictions=pred, references=ref)\n    bertscore_score = bertscore.compute(predictions=pred, references=ref, lang=\"en\")\n\n    #  dict\n    return {\"blue\":bleu_score[\"bleu\"],\n            \"precisions_1\":bleu_score[\"precisions\"][0],\n            \"precisions_2\":bleu_score[\"precisions\"][1],\n            \"precisions_3\":bleu_score[\"precisions\"][2],\n            \"precisions_4\":bleu_score[\"precisions\"][3],\n            \"bp\":bleu_score[\"brevity_penalty\"],\n            \"meteor\": meteor_score[\"meteor\"], \n            \"bertscore_f1\": np.average(bertscore_score[\"f1\"]), \n            \"bertscore_p\": np.average(bertscore_score[\"precision\"]), \n            \"bertscore_r\": np.average(bertscore_score[\"recall\"])}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:21.798300Z","iopub.execute_input":"2024-04-25T17:49:21.798659Z","iopub.status.idle":"2024-04-25T17:49:21.811167Z","shell.execute_reply.started":"2024-04-25T17:49:21.798623Z","shell.execute_reply":"2024-04-25T17:49:21.809906Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./T5\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=BATCH,\n    per_device_eval_batch_size=BATCH,\n    weight_decay=0.01,\n    save_total_limit=5,\n    num_train_epochs=12,\n    predict_with_generate=True,\n    save_strategy=\"epoch\",\n    fp16=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:21.812497Z","iopub.execute_input":"2024-04-25T17:49:21.812898Z","iopub.status.idle":"2024-04-25T17:49:22.571138Z","shell.execute_reply.started":"2024-04-25T17:49:21.812865Z","shell.execute_reply":"2024-04-25T17:49:22.570300Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_bleu(bp,precisions):\n    weights_1 = np.array([1,0,0,0])\n    weights_2 = np.array([0.5,0.5,0,0])\n    weights_3 = np.array([0.33,0.33,0.33,0])\n    weights_4 = np.array([0.25,0.25,0.25,0.25])\n    logp = np.log(precisions)\n        \n    res1 = bp*np.exp(np.dot(logp,weights_1))\n    res2 = bp*np.exp(np.dot(logp,weights_2))\n    res3 = bp*np.exp(np.dot(logp,weights_3))\n    res4 = bp*np.exp(np.dot(logp,weights_4))\n    \n    return [res1,res2,res3,res4]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:22.572226Z","iopub.execute_input":"2024-04-25T17:49:22.572513Z","iopub.status.idle":"2024-04-25T17:49:22.579598Z","shell.execute_reply.started":"2024-04-25T17:49:22.572485Z","shell.execute_reply":"2024-04-25T17:49:22.578697Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# results=trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:22.580700Z","iopub.execute_input":"2024-04-25T17:49:22.580967Z","iopub.status.idle":"2024-04-25T17:49:22.591391Z","shell.execute_reply.started":"2024-04-25T17:49:22.580944Z","shell.execute_reply":"2024-04-25T17:49:22.590474Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:22.592417Z","iopub.execute_input":"2024-04-25T17:49:22.592689Z","iopub.status.idle":"2024-04-25T17:49:22.602603Z","shell.execute_reply.started":"2024-04-25T17:49:22.592666Z","shell.execute_reply":"2024-04-25T17:49:22.601843Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import wandb\napi_key = \"9963cf6219e451d47251ea34645181ada1b2526b\"\nwandb.login(key=api_key)\nwandb.init()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:22.603539Z","iopub.execute_input":"2024-04-25T17:49:22.603786Z","iopub.status.idle":"2024-04-25T17:49:42.190316Z","shell.execute_reply.started":"2024-04-25T17:49:22.603764Z","shell.execute_reply":"2024-04-25T17:49:42.189334Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraghav21274\u001b[0m (\u001b[33mragha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240425_174925-dweo9c9g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ragha/uncategorized/runs/dweo9c9g' target=\"_blank\">curious-bird-129</a></strong> to <a href='https://wandb.ai/ragha/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ragha/uncategorized' target=\"_blank\">https://wandb.ai/ragha/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ragha/uncategorized/runs/dweo9c9g' target=\"_blank\">https://wandb.ai/ragha/uncategorized/runs/dweo9c9g</a>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ragha/uncategorized/runs/dweo9c9g?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7f65b3adee60>"},"metadata":{}}]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:42.193247Z","iopub.execute_input":"2024-04-25T17:49:42.193510Z","iopub.status.idle":"2024-04-25T17:50:16.157056Z","shell.execute_reply.started":"2024-04-25T17:49:42.193485Z","shell.execute_reply":"2024-04-25T17:50:16.155864Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22/22 00:17]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'bleu': 0.013412591507579901, 'precisions': [0.20336730172795747, 0.05232837253960634, 0.02566788894709272, 0.01555299539170507], 'brevity_penalty': 0.2954316776030752, 'length_ratio': 0.4505889399081653, 'translation_length': 2257, 'reference_length': 5009}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c330a965256049bbbb68ba921d804917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c6de1776c34f079a4f415e9d71cf6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a03af05af474a06afa4ff1abdd6d200"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29d38238a1d420ba87fbc61ac65c4cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f40bb10c3946829f05db2b9ad85fb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14097efec6984f24810b27cad8b3d018"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'eval_loss': 12.214547157287598, 'eval_blue': 0.013412591507579901, 'eval_precisions_1': 0.20336730172795747, 'eval_precisions_2': 0.05232837253960634, 'eval_precisions_3': 0.02566788894709272, 'eval_precisions_4': 0.01555299539170507, 'eval_bp': 0.2954316776030752, 'eval_meteor': 0.10502870207107545, 'eval_bertscore_f1': 0.8268550795385208, 'eval_bertscore_p': 0.835610826810201, 'eval_bertscore_r': 0.8188920545166937, 'eval_runtime': 33.9371, 'eval_samples_per_second': 5.127, 'eval_steps_per_second': 0.648}\n","output_type":"stream"}]},{"cell_type":"code","source":"calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:50:16.158569Z","iopub.execute_input":"2024-04-25T17:50:16.159228Z","iopub.status.idle":"2024-04-25T17:50:16.168105Z","shell.execute_reply.started":"2024-04-25T17:50:16.159188Z","shell.execute_reply":"2024-04-25T17:50:16.167233Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[0.06008114311910126,\n 0.030476580547208254,\n 0.019700255903496278,\n 0.013412591507579908]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}