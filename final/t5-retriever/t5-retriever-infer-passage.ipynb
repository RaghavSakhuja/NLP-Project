{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8052995,"sourceType":"datasetVersion","datasetId":4749278},{"sourceId":8204914,"sourceType":"datasetVersion","datasetId":4861131},{"sourceId":8209953,"sourceType":"datasetVersion","datasetId":4863826},{"sourceId":8229562,"sourceType":"datasetVersion","datasetId":4880165}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install accelerate -U\n! pip install evaluate\n! pip install sentence-transformers\n! pip install SentencePiece\n! pip install bert_score\n! pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:30:07.291948Z","iopub.execute_input":"2024-04-25T17:30:07.292249Z","iopub.status.idle":"2024-04-25T17:31:23.591904Z","shell.execute_reply.started":"2024-04-25T17:30:07.292218Z","shell.execute_reply":"2024-04-25T17:31:23.590818Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: bert_score in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.4)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.39.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.22.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#  import T5\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nimport numpy as np\nimport os\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DebertaTokenizer,\n    DebertaForSequenceClassification,\n    AutoConfig,\n)\n\nimport logging\nimport evaluate\nfrom evaluate import load\nfrom datasets import load_dataset\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import T5Tokenizer,T5ForConditionalGeneration\n\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu\n\nimport matplotlib.pyplot as plt\n\nfrom  transformers  import  AutoTokenizer, AutoModelWithLMHead\n\nimport csv\nfrom torch.utils.data import DataLoader, Dataset\nimport json\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\nimport numpy as np\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndevice=\"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'Using GPU: {torch.cuda.get_device_name()}')\nelse:\n    device = torch.device(\"cpu\")\n    print('Using CPU')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:23.597135Z","iopub.execute_input":"2024-04-25T17:31:23.597423Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2024-04-25 17:31:28.551579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-25 17:31:28.551645: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-25 17:31:28.553126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH=\"/kaggle/input/webis-clickbait-22/\"\nOUTPATH=\"/kaggle/working/\"\n# PATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\\"\n# OUTPATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\output\\\\\"\nBATCH=8\n# T5_model=\"/kaggle/input/nlpprojt5/T5_overall\"#phrase\nT5_model=\"/kaggle/input/t5-retriver/retriever_passage/T5_overall_passage\"\n# T5_model=\"/kaggle/input/nlpprojt5/T5_overall_multi\"\nsep='[SEP]'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag=\"passage\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.idle":"2024-04-25T17:31:31.370722Z","shell.execute_reply.started":"2024-04-25T17:31:31.080832Z","shell.execute_reply":"2024-04-25T17:31:31.369677Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_escape(l):\n    return l.replace(\"\\n\",\". \")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:31.372043Z","iopub.execute_input":"2024-04-25T17:31:31.372422Z","iopub.status.idle":"2024-04-25T17:31:31.381551Z","shell.execute_reply.started":"2024-04-25T17:31:31.372385Z","shell.execute_reply":"2024-04-25T17:31:31.380635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_label(x):\n    return \" \".join(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:31.382638Z","iopub.execute_input":"2024-04-25T17:31:31.382899Z","iopub.status.idle":"2024-04-25T17:31:31.392383Z","shell.execute_reply.started":"2024-04-25T17:31:31.382876Z","shell.execute_reply":"2024-04-25T17:31:31.391619Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_json(\"/kaggle/input/retriever/final_data_train.json\")\nval_data=pd.read_json(\"/kaggle/input/retriever/final_data_validation.json\")\ntest_data=pd.read_json(\"/kaggle/input/retriever/final_data_test.json\")\n\ntrain_data = train_data.replace({None: ''})\nval_data = val_data.replace({None: ''})\ntest_data = test_data.replace({None: ''})\n\ntrain_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/train.jsonl\",lines=True)\nval_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/validation.jsonl\",lines=True)\ntest_real=pd.read_json(\"/kaggle/input/webis-clickbait-22/test.jsonl\",lines=True)\n\ntrain_labels=train_real['spoiler'].apply(get_label)\nval_labels=val_real['spoiler'].apply(get_label)\ntest_labels=test_real['spoiler'].apply(get_label)\n\ntrain_tags=train_real['tags'].apply(get_label)\nval_tags=val_real['tags'].apply(get_label)\ntest_tags=test_real['tags'].apply(get_label)\n# train_type=train_real['spoiler']\ntrain_data['exctractedParagraph']=train_data['exctractedParagraph'].apply(remove_escape)\nval_data['exctractedParagraph']=val_data['exctractedParagraph'].apply(remove_escape)\ntest_data['exctractedParagraph']=test_data['exctractedParagraph'].apply(remove_escape)\n\ntrain_data['context']=train_data['targetTitle'] + ' ' + train_data['targetDescription']+\" \"+train_data['exctractedParagraph']\nval_data['context']=val_data['targetTitle'] + ' ' + val_data['targetDescription']+\" \"+val_data['exctractedParagraph']\ntest_data['context']=test_data['targetTitle'] + ' ' + test_data['targetDescription']+\" \"+test_data['exctractedParagraph']\n\ntrain_data['question']=train_data['postText']+\"?\"\nval_data['question']=val_data['postText']+'?'\ntest_data['question']=test_data['postText']+\"?\"\n\ntrain_data['spoiler']=train_labels\nval_data['spoiler']=val_labels\ntest_data['spoiler']=test_labels\n\ntrain_data['tags']=train_tags\nval_data['tags']=val_tags\ntest_data['tags']=test_tags\n\ntrain_data=train_data[train_data['tags']==tag]\nval_data=val_data[val_data['tags']==tag]\ntest_data=test_data[test_data['tags']==tag]\n\ntrain_data=train_data[['question','context','spoiler']]\n\nval_data=val_data[['question','context','spoiler']]\ntest_data=test_data[['question','context','spoiler']]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:31.393361Z","iopub.execute_input":"2024-04-25T17:31:31.393596Z","iopub.status.idle":"2024-04-25T17:31:32.227955Z","shell.execute_reply.started":"2024-04-25T17:31:31.393575Z","shell.execute_reply":"2024-04-25T17:31:32.226832Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:32.229597Z","iopub.execute_input":"2024-04-25T17:31:32.229942Z","iopub.status.idle":"2024-04-25T17:31:32.246349Z","shell.execute_reply.started":"2024-04-25T17:31:32.229896Z","shell.execute_reply":"2024-04-25T17:31:32.245373Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                               question  \\\n0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n5     What happens if your new AirPods get lost or s...   \n6     The Reason Why Gabor Kiraly Wears THOSE Tracki...   \n7     You’ll Never Believe What This Family Saw in t...   \n8                           Should you drink Red Wine??   \n...                                                 ...   \n3189  Women Reveal What They Think The Sexiest Part ...   \n3193  Here's another huge reason to eat a plant-base...   \n3194  If You See A Purple Butterfly Sticker At The H...   \n3195  Has Facebook's video explosion completely shak...   \n3196  Cop Is Eating At A Chili's When Teen Hands Him...   \n\n                                                context  \\\n0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n5     Here's what happens if your Apple AirPods get ...   \n6     The Reason Why Gabor Kiraly Wears THOSE Tracki...   \n7     You’ll Never Believe What This Family Saw in t...   \n8     Should I Drink Red Wine? Is red wine healthy a...   \n...                                                 ...   \n3189  Women Reveal What They Think The Sexiest Part ...   \n3193  Here's Another Huge Reason To Eat A Plant-Base...   \n3194  If You See A Purple Butterfly Sticker At The H...   \n3195  Facebook Video Surging, But YouTube Still Offe...   \n3196  Cop is eating at Chili's when teen hands him f...   \n\n                                                spoiler  \n0                   how about that morning we go throw?  \n5     Apple says that if AirPods are lost or stolen,...  \n6     \"The more good games I had in them, the more I...  \n7     rainbow colours in the sky and a halo spanning...  \n8     Red wine is clearly the drink of choice if you...  \n...                                                 ...  \n3189  almost every other part of a man is considered...  \n3193  may cut your risk for colorectal cancer -- the...  \n3194  one of her unborn twins had a condition called...  \n3195  it hasn’t necessarily taken the wind out of Yo...  \n3196             It read, \"Thanks for keeping us safe.\"  \n\n[1274 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>spoiler</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n      <td>how about that morning we go throw?</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What happens if your new AirPods get lost or s...</td>\n      <td>Here's what happens if your Apple AirPods get ...</td>\n      <td>Apple says that if AirPods are lost or stolen,...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The Reason Why Gabor Kiraly Wears THOSE Tracki...</td>\n      <td>The Reason Why Gabor Kiraly Wears THOSE Tracki...</td>\n      <td>\"The more good games I had in them, the more I...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>You’ll Never Believe What This Family Saw in t...</td>\n      <td>You’ll Never Believe What This Family Saw in t...</td>\n      <td>rainbow colours in the sky and a halo spanning...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Should you drink Red Wine??</td>\n      <td>Should I Drink Red Wine? Is red wine healthy a...</td>\n      <td>Red wine is clearly the drink of choice if you...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3189</th>\n      <td>Women Reveal What They Think The Sexiest Part ...</td>\n      <td>Women Reveal What They Think The Sexiest Part ...</td>\n      <td>almost every other part of a man is considered...</td>\n    </tr>\n    <tr>\n      <th>3193</th>\n      <td>Here's another huge reason to eat a plant-base...</td>\n      <td>Here's Another Huge Reason To Eat A Plant-Base...</td>\n      <td>may cut your risk for colorectal cancer -- the...</td>\n    </tr>\n    <tr>\n      <th>3194</th>\n      <td>If You See A Purple Butterfly Sticker At The H...</td>\n      <td>If You See A Purple Butterfly Sticker At The H...</td>\n      <td>one of her unborn twins had a condition called...</td>\n    </tr>\n    <tr>\n      <th>3195</th>\n      <td>Has Facebook's video explosion completely shak...</td>\n      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n      <td>it hasn’t necessarily taken the wind out of Yo...</td>\n    </tr>\n    <tr>\n      <th>3196</th>\n      <td>Cop Is Eating At A Chili's When Teen Hands Him...</td>\n      <td>Cop is eating at Chili's when teen hands him f...</td>\n      <td>It read, \"Thanks for keeping us safe.\"</td>\n    </tr>\n  </tbody>\n</table>\n<p>1274 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def preproc(data):\n    q=[]\n    c=[]\n    a=[]\n    # print(len(data))\n    # print(len(data['question']))\n    # print(len(data['context']))\n    # print(len(data['spoiler']))\n    for i in range(len(data['question'])):\n        q.append(data['question'][i])\n        c.append(data['context'][i])\n        if c[i]==None:\n            c[i]=\"\"\n        a.append(str(data['spoiler'][i]))\n    model_inputs=tokenizer(q,c,text_target=a,return_tensors='pt',padding=True,truncation=True,max_length=512)\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:32.247661Z","iopub.execute_input":"2024-04-25T17:31:32.248072Z","iopub.status.idle":"2024-04-25T17:31:32.255584Z","shell.execute_reply.started":"2024-04-25T17:31:32.248036Z","shell.execute_reply":"2024-04-25T17:31:32.254550Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(T5_model)\nmodel = AutoModelWithLMHead.from_pretrained(T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:32.257105Z","iopub.execute_input":"2024-04-25T17:31:32.257862Z","iopub.status.idle":"2024-04-25T17:31:33.142589Z","shell.execute_reply.started":"2024-04-25T17:31:32.257822Z","shell.execute_reply":"2024-04-25T17:31:33.141546Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\n\n### convert to Huggingface dataset\ntrain_dataset = Dataset(pa.Table.from_pandas(train_data)).remove_columns([\"__index_level_0__\"])\n\nval_dataset = Dataset(pa.Table.from_pandas(val_data)).remove_columns([\"__index_level_0__\"])\ntest_dataset = Dataset(pa.Table.from_pandas(test_data)).remove_columns([\"__index_level_0__\"])\ntrain_dataset,val_dataset,test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:33.144159Z","iopub.execute_input":"2024-04-25T17:31:33.144566Z","iopub.status.idle":"2024-04-25T17:31:33.217808Z","shell.execute_reply.started":"2024-04-25T17:31:33.144529Z","shell.execute_reply":"2024-04-25T17:31:33.216822Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 1274\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 322\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 403\n }))"},"metadata":{}}]},{"cell_type":"code","source":"# train_data=Dataset.from_pandas(train_df)\ntokenized_train=train_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_val=val_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_test=test_dataset.map(preproc,batched=True,batch_size=BATCH)\ntokenized_train,tokenized_val,tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:33.219031Z","iopub.execute_input":"2024-04-25T17:31:33.219388Z","iopub.status.idle":"2024-04-25T17:31:35.939654Z","shell.execute_reply.started":"2024-04-25T17:31:33.219359Z","shell.execute_reply":"2024-04-25T17:31:35.938734Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1274 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd807bf8a4d4ded90447245bd81d28b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/322 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d5fcb896c304650a500992d475a649a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/403 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2995f2a9ee6470cbd29f1836839a9ee"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 1274\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 322\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 403\n }))"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:35.944565Z","iopub.execute_input":"2024-04-25T17:31:35.944941Z","iopub.status.idle":"2024-04-25T17:31:35.950198Z","shell.execute_reply.started":"2024-04-25T17:31:35.944906Z","shell.execute_reply":"2024-04-25T17:31:35.949207Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(T5_model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:35.951412Z","iopub.execute_input":"2024-04-25T17:31:35.951708Z","iopub.status.idle":"2024-04-25T17:31:37.042561Z","shell.execute_reply.started":"2024-04-25T17:31:35.951683Z","shell.execute_reply":"2024-04-25T17:31:37.041667Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bertscore = load(\"bertscore\")\nmeteor = evaluate.load(\"meteor\")\nbleu = evaluate.load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:37.043670Z","iopub.execute_input":"2024-04-25T17:31:37.043918Z","iopub.status.idle":"2024-04-25T17:31:39.156151Z","shell.execute_reply.started":"2024-04-25T17:31:37.043896Z","shell.execute_reply":"2024-04-25T17:31:39.155165Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    pred, ref = postprocess_text(decoded_preds, decoded_labels)\n\n    # cal bleu, meteor and bert\n    bleu_score = bleu.compute(predictions=pred, references=ref)\n#     bleu1 = corpus_bleu(ref,pred,weights=(1,0,0,0))\n#     bleu2 = corpus_bleu(ref,pred,weights=(0.5,0.5,0))\n#     bleu3 = corpus_bleu(ref,pred,weights=(0.33,0.33,0.33,0)\n#     bleu4 = corpus_bleu(ref,pred,weights=(0.25,0.25,0.25,0.25))\n\n    print(bleu_score)\n    meteor_score = meteor.compute(predictions=pred, references=ref)\n    bertscore_score = bertscore.compute(predictions=pred, references=ref, lang=\"en\")\n\n    #  dict\n    return {\"blue\":bleu_score[\"bleu\"],\n            \"precisions_1\":bleu_score[\"precisions\"][0],\n            \"precisions_2\":bleu_score[\"precisions\"][1],\n            \"precisions_3\":bleu_score[\"precisions\"][2],\n            \"precisions_4\":bleu_score[\"precisions\"][3],\n            \"bp\":bleu_score[\"brevity_penalty\"],\n            \"meteor\": meteor_score[\"meteor\"], \n            \"bertscore_f1\": np.average(bertscore_score[\"f1\"]), \n            \"bertscore_p\": np.average(bertscore_score[\"precision\"]), \n            \"bertscore_r\": np.average(bertscore_score[\"recall\"])}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.157660Z","iopub.execute_input":"2024-04-25T17:31:39.158037Z","iopub.status.idle":"2024-04-25T17:31:39.170164Z","shell.execute_reply.started":"2024-04-25T17:31:39.158002Z","shell.execute_reply":"2024-04-25T17:31:39.169074Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./T5\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=BATCH,\n    per_device_eval_batch_size=BATCH,\n    weight_decay=0.01,\n    save_total_limit=5,\n    num_train_epochs=12,\n    predict_with_generate=True,\n    save_strategy=\"epoch\",\n    fp16=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.171575Z","iopub.execute_input":"2024-04-25T17:31:39.171904Z","iopub.status.idle":"2024-04-25T17:31:39.530480Z","shell.execute_reply.started":"2024-04-25T17:31:39.171875Z","shell.execute_reply":"2024-04-25T17:31:39.529515Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_bleu(bp,precisions):\n    weights_1 = np.array([1,0,0,0])\n    weights_2 = np.array([0.5,0.5,0,0])\n    weights_3 = np.array([0.33,0.33,0.33,0])\n    weights_4 = np.array([0.25,0.25,0.25,0.25])\n    logp = np.log(precisions)\n        \n    res1 = bp*np.exp(np.dot(logp,weights_1))\n    res2 = bp*np.exp(np.dot(logp,weights_2))\n    res3 = bp*np.exp(np.dot(logp,weights_3))\n    res4 = bp*np.exp(np.dot(logp,weights_4))\n    \n    return [res1,res2,res3,res4]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.532060Z","iopub.execute_input":"2024-04-25T17:31:39.532808Z","iopub.status.idle":"2024-04-25T17:31:39.540125Z","shell.execute_reply.started":"2024-04-25T17:31:39.532762Z","shell.execute_reply":"2024-04-25T17:31:39.539194Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# results=trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.541436Z","iopub.execute_input":"2024-04-25T17:31:39.542052Z","iopub.status.idle":"2024-04-25T17:31:39.550538Z","shell.execute_reply.started":"2024-04-25T17:31:39.542017Z","shell.execute_reply":"2024-04-25T17:31:39.549653Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.551695Z","iopub.execute_input":"2024-04-25T17:31:39.551984Z","iopub.status.idle":"2024-04-25T17:31:39.559796Z","shell.execute_reply.started":"2024-04-25T17:31:39.551960Z","shell.execute_reply":"2024-04-25T17:31:39.559062Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import wandb\napi_key = \"9963cf6219e451d47251ea34645181ada1b2526b\"\nwandb.login(key=api_key)\nwandb.init()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:39.560799Z","iopub.execute_input":"2024-04-25T17:31:39.561064Z","iopub.status.idle":"2024-04-25T17:31:59.390253Z","shell.execute_reply.started":"2024-04-25T17:31:39.561030Z","shell.execute_reply":"2024-04-25T17:31:59.389283Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraghav21274\u001b[0m (\u001b[33mragha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240425_173142-3nsztvy7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ragha/uncategorized/runs/3nsztvy7' target=\"_blank\">revived-gorge-128</a></strong> to <a href='https://wandb.ai/ragha/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ragha/uncategorized' target=\"_blank\">https://wandb.ai/ragha/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ragha/uncategorized/runs/3nsztvy7' target=\"_blank\">https://wandb.ai/ragha/uncategorized/runs/3nsztvy7</a>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ragha/uncategorized/runs/3nsztvy7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7bbd1b62f340>"},"metadata":{}}]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:59.391448Z","iopub.execute_input":"2024-04-25T17:31:59.391697Z","iopub.status.idle":"2024-04-25T17:32:47.222674Z","shell.execute_reply.started":"2024-04-25T17:31:59.391674Z","shell.execute_reply":"2024-04-25T17:32:47.221745Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [51/51 00:38]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'bleu': 0.027839987841166734, 'precisions': [0.19038534910339566, 0.06178962595577599, 0.04121621621621622, 0.032665181885671864], 'brevity_penalty': 0.4413096950102145, 'length_ratio': 0.5500524658971668, 'translation_length': 5242, 'reference_length': 9530}\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'eval_loss': 10.15523624420166, 'eval_blue': 0.027839987841166734, 'eval_precisions_1': 0.19038534910339566, 'eval_precisions_2': 0.06178962595577599, 'eval_precisions_3': 0.04121621621621622, 'eval_precisions_4': 0.032665181885671864, 'eval_bp': 0.4413096950102145, 'eval_meteor': 0.11294342066693827, 'eval_bertscore_f1': 0.8436320512821301, 'eval_bertscore_p': 0.8464283518696541, 'eval_bertscore_r': 0.8412937940498144, 'eval_runtime': 47.8031, 'eval_samples_per_second': 8.43, 'eval_steps_per_second': 1.067}\n","output_type":"stream"}]},{"cell_type":"code","source":"calculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:32:47.223994Z","iopub.execute_input":"2024-04-25T17:32:47.225542Z","iopub.status.idle":"2024-04-25T17:32:47.234789Z","shell.execute_reply.started":"2024-04-25T17:32:47.225511Z","shell.execute_reply":"2024-04-25T17:32:47.233672Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[0.08401890034723276,\n 0.04786499456032086,\n 0.03556289830856601,\n 0.027839987841166747]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}