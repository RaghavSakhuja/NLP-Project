{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8052995,"sourceType":"datasetVersion","datasetId":4749278}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U torchdata\n# !pip install -U spacy\n# !python -m spacy download en_core_web_lg\n# !python -m spacy download de_core_news_lg\n# !pip install portalocker\n! pip install accelerate -U\n! pip install evaluate\n! pip install sentence-transformers\n! pip install SentencePiece\n! pip install bert_score\n! pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:19:59.015770Z","iopub.execute_input":"2024-04-23T20:19:59.016174Z","iopub.status.idle":"2024-04-23T20:21:11.717314Z","shell.execute_reply.started":"2024-04-23T20:19:59.016136Z","shell.execute_reply":"2024-04-23T20:21:11.716276Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: bert_score in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.4)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.39.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.22.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#  import T5\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nimport numpy as np\nimport os\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DebertaTokenizer,\n    DebertaForSequenceClassification,\n    AutoConfig,\n)\n\nimport logging\nimport evaluate\nfrom evaluate import load\nfrom datasets import load_dataset\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import T5Tokenizer,T5ForConditionalGeneration\n\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu\n\nimport matplotlib.pyplot as plt\n\nfrom  transformers  import  AutoTokenizer, AutoModelWithLMHead\n\nimport csv\nfrom torch.utils.data import DataLoader, Dataset\nimport json\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\nimport numpy as np\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndevice=\"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'Using GPU: {torch.cuda.get_device_name()}')\nelse:\n    device = torch.device(\"cpu\")\n    print('Using CPU')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:11.719864Z","iopub.execute_input":"2024-04-23T20:21:11.720747Z","iopub.status.idle":"2024-04-23T20:21:11.733341Z","shell.execute_reply.started":"2024-04-23T20:21:11.720705Z","shell.execute_reply":"2024-04-23T20:21:11.732364Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH=\"/kaggle/input/webis-clickbait-22/\"\nOUTPATH=\"/kaggle/working/\"\n# PATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\\"\n# OUTPATH=\"D:\\\\ghd\\\\NLP-Project\\\\webis-clickbait-22\\\\output\\\\\"\nBATCH=8\nT5_model = \"/kaggle/input/t5-dataset-proj/T5/checkpoint-3200\"\nsep='[SEP]'","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:11.734234Z","iopub.execute_input":"2024-04-23T20:21:11.734489Z","iopub.status.idle":"2024-04-23T20:21:11.746965Z","shell.execute_reply.started":"2024-04-23T20:21:11.734458Z","shell.execute_reply":"2024-04-23T20:21:11.746128Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# data=pd.read_json(PATH+\"train.jsonl\",lines=True,encoding='utf-8')\n# data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:11.748820Z","iopub.execute_input":"2024-04-23T20:21:11.749111Z","iopub.status.idle":"2024-04-23T20:21:11.760232Z","shell.execute_reply.started":"2024-04-23T20:21:11.749078Z","shell.execute_reply":"2024-04-23T20:21:11.759392Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def get_split_data(file_path,if_train=True):\n    global label_encoder\n    data=pd.read_json(file_path,lines=True,encoding='utf-8')\n\n\n    y = data[\"spoiler\"]\n    Y=[]\n    for i in y:\n        Y.append(\" \".join(i))\n        \n    new_data=data[['postText','targetParagraphs','targetTitle','targetDescription','targetKeywords']]\n    dic=new_data.to_dict(orient='records')\n\n    for i in dic:\n        # print(i)\n        i['postText']=i['postText'][0]\n        targetparah=\" \".join(i['targetParagraphs'])\n        i['targetParagraphs']=targetparah\n        # if(targetDescription is None or len(targetDescription)==0):\n        #     targetDescription='none'\n        #     desccount+=1\n        # i['targetDescription']='targetDescription: '+targetDescription\n        # targetkey=i['targetKeywords']\n        # if(targetkey is None or len(targetkey)==0):\n        #     targetkey='none'\n        #     keycount+=1\n        # i['targetKeywords']='targetKeywords: '+targetkey\n        i['question']=\"question : \"+i['postText']+\"?\"\n        i['context']=\"context : \"+i['targetParagraphs']\n        del i['postText']\n        del i['targetParagraphs']\n        del i['targetTitle']\n        del i['targetDescription']\n        del i['targetKeywords']\n\n    # print(\"desccount: \",desccount)\n    # print(\"keycount: \",keycount)\n    X_q = [i['question'] for i in dic]\n    X_q=np.array(X_q)\n    X_c = [i['context'] for i in dic]\n    X_c=np.array(X_c)\n\n    return X_q[:100],X_c[:100],Y[:100]\n#     return X_q,X_c,Y","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:11.761257Z","iopub.execute_input":"2024-04-23T20:21:11.761490Z","iopub.status.idle":"2024-04-23T20:21:11.773011Z","shell.execute_reply.started":"2024-04-23T20:21:11.761470Z","shell.execute_reply":"2024-04-23T20:21:11.772157Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_train_q,x_train_c,y_train = get_split_data(PATH+'train.jsonl')\nx_test_q,x_test_c,y_test = get_split_data(PATH+'test.jsonl',False)\nx_val_q,x_val_c,y_val = get_split_data(PATH+'validation.jsonl',False)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:11.774022Z","iopub.execute_input":"2024-04-23T20:21:11.774283Z","iopub.status.idle":"2024-04-23T20:21:14.111715Z","shell.execute_reply.started":"2024-04-23T20:21:11.774260Z","shell.execute_reply":"2024-04-23T20:21:14.110926Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"x_train_q.shape,x_train_c.shape,len(y_train),x_test_q.shape,x_test_c.shape,len(y_test),x_val_q.shape,x_val_c.shape,len(y_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:14.113079Z","iopub.execute_input":"2024-04-23T20:21:14.113357Z","iopub.status.idle":"2024-04-23T20:21:14.119939Z","shell.execute_reply.started":"2024-04-23T20:21:14.113332Z","shell.execute_reply":"2024-04-23T20:21:14.119033Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((100,), (100,), 100, (100,), (100,), 100, (100,), (100,), 100)"},"metadata":{}}]},{"cell_type":"code","source":"# create pd dataframe\ntrain_df = pd.DataFrame(list(zip(x_train_q, x_train_c, y_train)), columns =['question', 'context', 'spoiler'])\nval_df = pd.DataFrame(list(zip(x_val_q, x_val_c, y_val)), columns =['question', 'context', 'spoiler'])\ntest_df = pd.DataFrame(list(zip(x_test_q, x_test_c, y_test)), columns =['question', 'context', 'spoiler'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:14.121261Z","iopub.execute_input":"2024-04-23T20:21:14.121689Z","iopub.status.idle":"2024-04-23T20:21:14.180742Z","shell.execute_reply.started":"2024-04-23T20:21:14.121657Z","shell.execute_reply":"2024-04-23T20:21:14.179887Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_df[\"question\"][0],train_df[\"context\"][0],train_df[\"spoiler\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:14.181877Z","iopub.execute_input":"2024-04-23T20:21:14.182211Z","iopub.status.idle":"2024-04-23T20:21:14.189168Z","shell.execute_reply.started":"2024-04-23T20:21:14.182181Z","shell.execute_reply":"2024-04-23T20:21:14.188223Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"('question : Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had Better Idea?',\n 'context : It’ll be just like old times this weekend for Tom Brady and Wes Welker. Welker revealed Friday morning on a Miami radio station that he contacted Brady because he’ll be in town for Sunday’s game between the New England Patriots and Miami Dolphins at Gillette Stadium. It seemed like a perfect opportunity for the two to catch up. But Brady’s definition of \"catching up\" involves far more than just a meal. In fact, it involves some literal \"catching\" as the Patriots quarterback looks to stay sharp during his four-game Deflategate suspension. \"I hit him up to do dinner Saturday night. He’s like, ‘I’m going to be flying in from Ann Arbor later (after the Michigan-Colorado football game), but how about that morning we go throw?’ \" Welker said on WQAM, per The Boston Globe. \"And I’m just sitting there, I’m like, ‘I was just thinking about dinner, but yeah, sure. I’ll get over there early and we can throw a little bit.’ \" Welker was one of Brady’s favorite targets for six seasons from 2007 to 2012. It’s understandable him and Brady want to meet with both being in the same area. But Brady typically is all business during football season. Welker probably should have known what he was getting into when reaching out to his buddy. \"That’s the only thing we really have planned,\" Welker said of his upcoming workout with Brady. \"It’s just funny. I’m sitting there trying to have dinner. ‘Hey, get your ass up here and let’s go throw.’ I’m like, ‘Aw jeez, man.’ He’s going to have me running like 2-minute drills in his backyard or something.\" Maybe Brady will put a good word in for Welker down in Foxboro if the former Patriots wide receiver impresses him enough.',\n 'how about that morning we go throw?')"},"metadata":{}}]},{"cell_type":"code","source":"# t5\ntokenizer = AutoTokenizer.from_pretrained(T5_model)\nmodel = AutoModelWithLMHead.from_pretrained(T5_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:14.193329Z","iopub.execute_input":"2024-04-23T20:21:14.193656Z","iopub.status.idle":"2024-04-23T20:21:21.202521Z","shell.execute_reply.started":"2024-04-23T20:21:14.193634Z","shell.execute_reply":"2024-04-23T20:21:21.201590Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pyarrow as pa\nimport pyarrow.dataset as ds\nimport pandas as pd\nfrom datasets import Dataset\n\n### convert to Huggingface dataset\ntrain_data = Dataset(pa.Table.from_pandas(train_df))\nval_data = Dataset(pa.Table.from_pandas(val_df))\ntest_data = Dataset(pa.Table.from_pandas(test_df))\ntrain_data,val_data,test_data","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:21.203817Z","iopub.execute_input":"2024-04-23T20:21:21.204280Z","iopub.status.idle":"2024-04-23T20:21:21.283969Z","shell.execute_reply.started":"2024-04-23T20:21:21.204245Z","shell.execute_reply":"2024-04-23T20:21:21.283136Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 100\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 100\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler'],\n     num_rows: 100\n }))"},"metadata":{}}]},{"cell_type":"code","source":"\ntrain_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:21.285061Z","iopub.execute_input":"2024-04-23T20:21:21.285322Z","iopub.status.idle":"2024-04-23T20:21:21.293711Z","shell.execute_reply.started":"2024-04-23T20:21:21.285300Z","shell.execute_reply":"2024-04-23T20:21:21.292895Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'question': 'question : Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had Better Idea?',\n 'context': 'context : It’ll be just like old times this weekend for Tom Brady and Wes Welker. Welker revealed Friday morning on a Miami radio station that he contacted Brady because he’ll be in town for Sunday’s game between the New England Patriots and Miami Dolphins at Gillette Stadium. It seemed like a perfect opportunity for the two to catch up. But Brady’s definition of \"catching up\" involves far more than just a meal. In fact, it involves some literal \"catching\" as the Patriots quarterback looks to stay sharp during his four-game Deflategate suspension. \"I hit him up to do dinner Saturday night. He’s like, ‘I’m going to be flying in from Ann Arbor later (after the Michigan-Colorado football game), but how about that morning we go throw?’ \" Welker said on WQAM, per The Boston Globe. \"And I’m just sitting there, I’m like, ‘I was just thinking about dinner, but yeah, sure. I’ll get over there early and we can throw a little bit.’ \" Welker was one of Brady’s favorite targets for six seasons from 2007 to 2012. It’s understandable him and Brady want to meet with both being in the same area. But Brady typically is all business during football season. Welker probably should have known what he was getting into when reaching out to his buddy. \"That’s the only thing we really have planned,\" Welker said of his upcoming workout with Brady. \"It’s just funny. I’m sitting there trying to have dinner. ‘Hey, get your ass up here and let’s go throw.’ I’m like, ‘Aw jeez, man.’ He’s going to have me running like 2-minute drills in his backyard or something.\" Maybe Brady will put a good word in for Welker down in Foxboro if the former Patriots wide receiver impresses him enough.',\n 'spoiler': 'how about that morning we go throw?'}"},"metadata":{}}]},{"cell_type":"code","source":"def preproc(data):\n    q=[]\n    c=[]\n    a=[]\n    # print(len(data))\n    # print(len(data['question']))\n    # print(len(data['context']))\n    # print(len(data['spoiler']))\n    for i in range(len(data['question'])):\n        q.append(data['question'][i])\n        c.append(data['context'][i])\n        a.append(data['spoiler'][i])\n\n    model_inputs=tokenizer(q,c,text_target=a,return_tensors='pt',padding=True,truncation=True,max_length=512)\n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:21.294836Z","iopub.execute_input":"2024-04-23T20:21:21.295120Z","iopub.status.idle":"2024-04-23T20:21:21.302855Z","shell.execute_reply.started":"2024-04-23T20:21:21.295092Z","shell.execute_reply":"2024-04-23T20:21:21.302029Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# train_data=Dataset.from_pandas(train_df)\ntokenized_train=train_data.map(preproc,batched=True,batch_size=BATCH)\ntokenized_val=val_data.map(preproc,batched=True,batch_size=BATCH)\ntokenized_test=test_data.map(preproc,batched=True,batch_size=BATCH)\ntokenized_train,tokenized_val,tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:21.303874Z","iopub.execute_input":"2024-04-23T20:21:21.304163Z","iopub.status.idle":"2024-04-23T20:21:22.306943Z","shell.execute_reply.started":"2024-04-23T20:21:21.304140Z","shell.execute_reply":"2024-04-23T20:21:22.306049Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11777a9505f349be869cc17042c24184"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46e2fd3dbe8476a969dc887824662c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c59d7317c342b5ba5e2da12190990e"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 100\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 100\n }),\n Dataset({\n     features: ['question', 'context', 'spoiler', 'input_ids', 'attention_mask', 'labels'],\n     num_rows: 100\n }))"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=T5_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:22.308275Z","iopub.execute_input":"2024-04-23T20:21:22.308629Z","iopub.status.idle":"2024-04-23T20:21:22.313476Z","shell.execute_reply.started":"2024-04-23T20:21:22.308596Z","shell.execute_reply":"2024-04-23T20:21:22.312481Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import wandb\napi_key = \"9963cf6219e451d47251ea34645181ada1b2526b\"\nwandb.login(key=api_key)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:22.314610Z","iopub.execute_input":"2024-04-23T20:21:22.314927Z","iopub.status.idle":"2024-04-23T20:21:25.370680Z","shell.execute_reply.started":"2024-04-23T20:21:22.314898Z","shell.execute_reply":"2024-04-23T20:21:25.369824Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(T5_model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:25.371828Z","iopub.execute_input":"2024-04-23T20:21:25.372564Z","iopub.status.idle":"2024-04-23T20:21:26.523350Z","shell.execute_reply.started":"2024-04-23T20:21:25.372535Z","shell.execute_reply":"2024-04-23T20:21:26.522478Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"bertscore = load(\"bertscore\")\nmeteor = evaluate.load(\"meteor\")\nbleu = evaluate.load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:26.524496Z","iopub.execute_input":"2024-04-23T20:21:26.524781Z","iopub.status.idle":"2024-04-23T20:21:29.932762Z","shell.execute_reply.started":"2024-04-23T20:21:26.524757Z","shell.execute_reply":"2024-04-23T20:21:29.931946Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ae91fb2a364f30975402fc1d416395"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca01f07f946f4555b24b495b09133e6a"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62739c37b6274181a0f3f434890dce48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c86019873d54055beb4644a7fb291a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"576e3536cf584d398a4277d97cbf1369"}},"metadata":{}}]},{"cell_type":"code","source":"\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    pred, ref = postprocess_text(decoded_preds, decoded_labels)\n\n    # cal bleu, meteor and bert\n    bleu_score = bleu.compute(predictions=pred, references=ref)\n#     bleu1 = corpus_bleu(ref,pred,weights=(1,0,0,0))\n#     bleu2 = corpus_bleu(ref,pred,weights=(0.5,0.5,0))\n#     bleu3 = corpus_bleu(ref,pred,weights=(0.33,0.33,0.33,0)\n#     bleu4 = corpus_bleu(ref,pred,weights=(0.25,0.25,0.25,0.25))\n\n    print(bleu_score)\n    meteor_score = meteor.compute(predictions=pred, references=ref)\n    bertscore_score = bertscore.compute(predictions=pred, references=ref, lang=\"en\")\n\n    #  dict\n    return {\"blue\":bleu_score[\"bleu\"],\n            \"precisions_1\":bleu_score[\"precisions\"][0],\n            \"precisions_2\":bleu_score[\"precisions\"][1],\n            \"precisions_3\":bleu_score[\"precisions\"][2],\n            \"precisions_4\":bleu_score[\"precisions\"][3],\n            \"bp\":bleu_score[\"brevity_penalty\"],\n            \"meteor\": meteor_score[\"meteor\"], \n            \"bertscore_f1\": np.average(bertscore_score[\"f1\"]), \n            \"bertscore_p\": np.average(bertscore_score[\"precision\"]), \n            \"bertscore_r\": np.average(bertscore_score[\"recall\"])}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:29.934033Z","iopub.execute_input":"2024-04-23T20:21:29.934320Z","iopub.status.idle":"2024-04-23T20:21:29.944634Z","shell.execute_reply.started":"2024-04-23T20:21:29.934296Z","shell.execute_reply":"2024-04-23T20:21:29.943428Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./T5\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=BATCH,\n    per_device_eval_batch_size=BATCH,\n    weight_decay=0.01,\n    save_total_limit=5,\n    num_train_epochs=12,\n    predict_with_generate=True,\n    save_strategy=\"epoch\",\n    fp16=True,\n#     report_to=\"wandb\",\n#     logging_dir='./lolololol'\n\n    # push_to_hub=True\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"bleu\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:21:29.945879Z","iopub.execute_input":"2024-04-23T20:21:29.946457Z","iopub.status.idle":"2024-04-23T20:26:46.736166Z","shell.execute_reply.started":"2024-04-23T20:21:29.946425Z","shell.execute_reply":"2024-04-23T20:26:46.735089Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraghav21274\u001b[0m (\u001b[33mragha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240423_202130-gzi1x7vz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ragha/huggingface/runs/gzi1x7vz' target=\"_blank\">magic-snowball-42</a></strong> to <a href='https://wandb.ai/ragha/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ragha/huggingface' target=\"_blank\">https://wandb.ai/ragha/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ragha/huggingface/runs/gzi1x7vz' target=\"_blank\">https://wandb.ai/ragha/huggingface/runs/gzi1x7vz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [156/156 04:57, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Blue</th>\n      <th>Precisions 1</th>\n      <th>Precisions 2</th>\n      <th>Precisions 3</th>\n      <th>Precisions 4</th>\n      <th>Bp</th>\n      <th>Meteor</th>\n      <th>Bertscore F1</th>\n      <th>Bertscore P</th>\n      <th>Bertscore R</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.381750</td>\n      <td>0.106438</td>\n      <td>0.529323</td>\n      <td>0.437168</td>\n      <td>0.397089</td>\n      <td>0.373206</td>\n      <td>0.247340</td>\n      <td>0.402683</td>\n      <td>0.905541</td>\n      <td>0.915388</td>\n      <td>0.897024</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.381557</td>\n      <td>0.120038</td>\n      <td>0.499307</td>\n      <td>0.410628</td>\n      <td>0.370577</td>\n      <td>0.346723</td>\n      <td>0.297953</td>\n      <td>0.403098</td>\n      <td>0.904696</td>\n      <td>0.912898</td>\n      <td>0.897793</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.382017</td>\n      <td>0.115957</td>\n      <td>0.495105</td>\n      <td>0.403252</td>\n      <td>0.363465</td>\n      <td>0.340471</td>\n      <td>0.292477</td>\n      <td>0.397076</td>\n      <td>0.904339</td>\n      <td>0.912713</td>\n      <td>0.897220</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.384120</td>\n      <td>0.111891</td>\n      <td>0.513043</td>\n      <td>0.420339</td>\n      <td>0.381423</td>\n      <td>0.359729</td>\n      <td>0.269781</td>\n      <td>0.400584</td>\n      <td>0.904678</td>\n      <td>0.913017</td>\n      <td>0.897603</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.384805</td>\n      <td>0.103127</td>\n      <td>0.498538</td>\n      <td>0.397260</td>\n      <td>0.354000</td>\n      <td>0.330275</td>\n      <td>0.264369</td>\n      <td>0.397184</td>\n      <td>0.904211</td>\n      <td>0.912280</td>\n      <td>0.897379</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.385710</td>\n      <td>0.102968</td>\n      <td>0.499268</td>\n      <td>0.397942</td>\n      <td>0.354709</td>\n      <td>0.331034</td>\n      <td>0.263469</td>\n      <td>0.397188</td>\n      <td>0.904517</td>\n      <td>0.912729</td>\n      <td>0.897547</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.387828</td>\n      <td>0.100253</td>\n      <td>0.498521</td>\n      <td>0.397569</td>\n      <td>0.353659</td>\n      <td>0.329439</td>\n      <td>0.257178</td>\n      <td>0.389842</td>\n      <td>0.904151</td>\n      <td>0.912661</td>\n      <td>0.896893</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.389030</td>\n      <td>0.105056</td>\n      <td>0.481481</td>\n      <td>0.382060</td>\n      <td>0.339768</td>\n      <td>0.314159</td>\n      <td>0.280648</td>\n      <td>0.386728</td>\n      <td>0.902021</td>\n      <td>0.909714</td>\n      <td>0.895530</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.390439</td>\n      <td>0.106096</td>\n      <td>0.476728</td>\n      <td>0.377668</td>\n      <td>0.335238</td>\n      <td>0.309368</td>\n      <td>0.287010</td>\n      <td>0.385926</td>\n      <td>0.901672</td>\n      <td>0.909097</td>\n      <td>0.895443</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>0.391527</td>\n      <td>0.105056</td>\n      <td>0.481481</td>\n      <td>0.382060</td>\n      <td>0.339768</td>\n      <td>0.314159</td>\n      <td>0.280648</td>\n      <td>0.385819</td>\n      <td>0.902146</td>\n      <td>0.909979</td>\n      <td>0.895510</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>0.392350</td>\n      <td>0.106096</td>\n      <td>0.476728</td>\n      <td>0.377668</td>\n      <td>0.335238</td>\n      <td>0.309368</td>\n      <td>0.287010</td>\n      <td>0.385017</td>\n      <td>0.901797</td>\n      <td>0.909362</td>\n      <td>0.895423</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>0.392677</td>\n      <td>0.106096</td>\n      <td>0.476728</td>\n      <td>0.377668</td>\n      <td>0.335238</td>\n      <td>0.309368</td>\n      <td>0.287010</td>\n      <td>0.385017</td>\n      <td>0.901797</td>\n      <td>0.909362</td>\n      <td>0.895423</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10643768175587211, 'precisions': [0.5293233082706766, 0.43716814159292033, 0.3970893970893971, 0.37320574162679426], 'brevity_penalty': 0.24733972532047963, 'length_ratio': 0.41718946047678795, 'translation_length': 665, 'reference_length': 1594}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff75b87aee4845c59f3a8f518659344c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89aceee0c20c4d62a78af0e0cbf54108"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7e5705a90fc4968ae2a900517733aab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"637ed4a2601e44a0833de17338f6359d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e205c8912aee4356846214fa39673045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5dbd44ffd84094995d71bc852197ec"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.12003768712022717, 'precisions': [0.49930651872399445, 0.4106280193236715, 0.37057728119180633, 0.346723044397463], 'brevity_penalty': 0.2979533620520462, 'length_ratio': 0.4523212045169385, 'translation_length': 721, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.11595656019168434, 'precisions': [0.4951048951048951, 0.4032520325203252, 0.3634651600753296, 0.3404710920770878], 'brevity_penalty': 0.2924765959462062, 'length_ratio': 0.4485570890840652, 'translation_length': 715, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.11189100105837037, 'precisions': [0.5130434782608696, 0.42033898305084744, 0.3814229249011858, 0.3597285067873303], 'brevity_penalty': 0.26978095486220116, 'length_ratio': 0.4328732747804266, 'translation_length': 690, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10312731903111007, 'precisions': [0.49853801169590645, 0.3972602739726027, 0.354, 0.3302752293577982], 'brevity_penalty': 0.26436901791085377, 'length_ratio': 0.42910915934755334, 'translation_length': 684, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10296829031235173, 'precisions': [0.4992679355783309, 0.3979416809605489, 0.35470941883767537, 0.3310344827586207], 'brevity_penalty': 0.26346852277887145, 'length_ratio': 0.42848180677540776, 'translation_length': 683, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10025294897597666, 'precisions': [0.4985207100591716, 0.3975694444444444, 0.35365853658536583, 0.3294392523364486], 'brevity_penalty': 0.25717765567594597, 'length_ratio': 0.424090338770389, 'translation_length': 676, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10505636385289412, 'precisions': [0.48148148148148145, 0.38205980066445183, 0.33976833976833976, 0.3141592920353982], 'brevity_penalty': 0.2806476613360785, 'length_ratio': 0.44040150564617314, 'translation_length': 702, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10609626295267459, 'precisions': [0.4767277856135402, 0.37766830870279144, 0.3352380952380952, 0.3093681917211329], 'brevity_penalty': 0.2870103636902272, 'length_ratio': 0.44479297365119197, 'translation_length': 709, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10505636385289412, 'precisions': [0.48148148148148145, 0.38205980066445183, 0.33976833976833976, 0.3141592920353982], 'brevity_penalty': 0.2806476613360785, 'length_ratio': 0.44040150564617314, 'translation_length': 702, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10609626295267459, 'precisions': [0.4767277856135402, 0.37766830870279144, 0.3352380952380952, 0.3093681917211329], 'brevity_penalty': 0.2870103636902272, 'length_ratio': 0.44479297365119197, 'translation_length': 709, 'reference_length': 1594}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'bleu': 0.10609626295267459, 'precisions': [0.4767277856135402, 0.37766830870279144, 0.3352380952380952, 0.3093681917211329], 'brevity_penalty': 0.2870103636902272, 'length_ratio': 0.44479297365119197, 'translation_length': 709, 'reference_length': 1594}\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=156, training_loss=0.3604861283913637, metrics={'train_runtime': 316.3504, 'train_samples_per_second': 3.793, 'train_steps_per_second': 0.493, 'total_flos': 730749468672000.0, 'train_loss': 0.3604861283913637, 'epoch': 12.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"T5_overall\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:26:46.739178Z","iopub.execute_input":"2024-04-23T20:26:46.739560Z","iopub.status.idle":"2024-04-23T20:26:48.028499Z","shell.execute_reply.started":"2024-04-23T20:26:46.739523Z","shell.execute_reply":"2024-04-23T20:26:48.027205Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:26:48.030164Z","iopub.execute_input":"2024-04-23T20:26:48.031583Z","iopub.status.idle":"2024-04-23T20:26:48.747171Z","shell.execute_reply.started":"2024-04-23T20:26:48.031542Z","shell.execute_reply":"2024-04-23T20:26:48.742991Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:26:48.748942Z","iopub.execute_input":"2024-04-23T20:26:48.749534Z","iopub.status.idle":"2024-04-23T20:27:12.932888Z","shell.execute_reply.started":"2024-04-23T20:26:48.749498Z","shell.execute_reply":"2024-04-23T20:27:12.930774Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 00:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'bleu': 0.10952088394040538, 'precisions': [0.4387254901960784, 0.32821229050279327, 0.2845786963434022, 0.2572463768115942], 'brevity_penalty': 0.34180003299598605, 'length_ratio': 0.48226950354609927, 'translation_length': 816, 'reference_length': 1692}\n{'eval_loss': 0.3629412055015564, 'eval_blue': 0.10952088394040538, 'eval_precisions_1': 0.4387254901960784, 'eval_precisions_2': 0.32821229050279327, 'eval_precisions_3': 0.2845786963434022, 'eval_precisions_4': 0.2572463768115942, 'eval_bp': 0.34180003299598605, 'eval_meteor': 0.3564716308562745, 'eval_bertscore_f1': 0.890163699388504, 'eval_bertscore_p': 0.8973866164684295, 'eval_bertscore_r': 0.8840654218196868, 'eval_runtime': 11.5238, 'eval_samples_per_second': 8.678, 'eval_steps_per_second': 1.128, 'epoch': 12.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_bleu(bp,precisions):\n    weights_1 = np.array([1,0,0,0])\n    weights_2 = np.array([0.5,0.5,0,0])\n    weights_3 = np.array([0.33,0.33,0.33,0])\n    weights_4 = np.array([0.25,0.25,0.25,0.25])\n    logp = np.log(precisions)\n        \n    res1 = bp*np.exp(np.dot(logp,weights_1))\n    res2 = bp*np.exp(np.dot(logp,weights_2))\n    res3 = bp*np.exp(np.dot(logp,weights_3))\n    res4 = bp*np.exp(np.dot(logp,weights_4))\n    \n    return [res1,res2,res3,res4]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:27:12.934429Z","iopub.execute_input":"2024-04-23T20:27:12.934786Z","iopub.status.idle":"2024-04-23T20:27:12.948725Z","shell.execute_reply.started":"2024-04-23T20:27:12.934751Z","shell.execute_reply":"2024-04-23T20:27:12.947759Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_train)\nprint(results)\ncalculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_val)\nprint(results)\ncalculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(results)\ncalculate_bleu(results['eval_bp'],[results['eval_precisions_1'],results['eval_precisions_2'],results['eval_precisions_3'],results['eval_precisions_4']])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:27:12.934429Z","iopub.execute_input":"2024-04-23T20:27:12.934786Z","iopub.status.idle":"2024-04-23T20:27:12.948725Z","shell.execute_reply.started":"2024-04-23T20:27:12.934751Z","shell.execute_reply":"2024-04-23T20:27:12.947759Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[0.14995638702519976,\n 0.12970178535938756,\n 0.1191005127286421,\n 0.10952088394040536]"},"metadata":{}}]},{"cell_type":"code","source":"q='question : Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had Better Idea?'\nc='context : It’ll be just like old times this weekend for Tom Brady and Wes Welker. Welker revealed Friday morning on a Miami radio station that he contacted Brady because he’ll be in town for Sunday’s game between the New England Patriots and Miami Dolphins at Gillette Stadium. It seemed like a perfect opportunity for the two to catch up. But Brady’s definition of \"catching up\" involves far more than just a meal. In fact, it involves some literal \"catching\" as the Patriots quarterback looks to stay sharp during his four-game Deflategate suspension. \"I hit him up to do dinner Saturday night. He’s like, ‘I’m going to be flying in from Ann Arbor later (after the Michigan-Colorado football game), but how about that morning we go throw?’ \" Welker said on WQAM, per The Boston Globe. \"And I’m just sitting there, I’m like, ‘I was just thinking about dinner, but yeah, sure. I’ll get over there early and we can throw a little bit.’ \" Welker was one of Brady’s favorite targets for six seasons from 2007 to 2012. It’s understandable him and Brady want to meet with both being in the same area. But Brady typically is all business during football season. Welker probably should have known what he was getting into when reaching out to his buddy. \"That’s the only thing we really have planned,\" Welker said of his upcoming workout with Brady. \"It’s just funny. I’m sitting there trying to have dinner. ‘Hey, get your ass up here and let’s go throw.’ I’m like, ‘Aw jeez, man.’ He’s going to have me running like 2-minute drills in his backyard or something.\" Maybe Brady will put a good word in for Welker down in Foxboro if the former Patriots wide receiver impresses him enough.'\nenc=tokenizer(q+\" \"+c,return_tensors='pt',padding=True,truncation=True,max_length=512)\nout=model.generate(input_ids=enc['input_ids'].to(device))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:27:12.950416Z","iopub.execute_input":"2024-04-23T20:27:12.950740Z","iopub.status.idle":"2024-04-23T20:27:14.092620Z","shell.execute_reply.started":"2024-04-23T20:27:12.950710Z","shell.execute_reply":"2024-04-23T20:27:14.091538Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(out[0]),'how about that morning we go throw?'","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:27:14.094109Z","iopub.execute_input":"2024-04-23T20:27:14.094493Z","iopub.status.idle":"2024-04-23T20:27:14.103588Z","shell.execute_reply.started":"2024-04-23T20:27:14.094453Z","shell.execute_reply":"2024-04-23T20:27:14.102425Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('<pad> how about that morning we go throw?</s>',\n 'how about that morning we go throw?')"},"metadata":{}}]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T20:28:48.058286Z","iopub.execute_input":"2024-04-23T20:28:48.058905Z","iopub.status.idle":"2024-04-23T20:28:48.079034Z","shell.execute_reply.started":"2024-04-23T20:28:48.058873Z","shell.execute_reply":"2024-04-23T20:28:48.078000Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"/kaggle/working/wandb/debug.log\n/kaggle/working/wandb/debug-internal.log\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/run-gzi1x7vz.wandb\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/requirements.txt\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/wandb-metadata.json\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/conda-environment.yaml\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/output.log\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/wandb-summary.json\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/files/config.yaml\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/logs/debug.log\n/kaggle/working/wandb/run-20240423_202130-gzi1x7vz/logs/debug-internal.log\n/kaggle/working/T5/checkpoint-143/trainer_state.json\n/kaggle/working/T5/checkpoint-143/spiece.model\n/kaggle/working/T5/checkpoint-143/optimizer.pt\n/kaggle/working/T5/checkpoint-143/scheduler.pt\n/kaggle/working/T5/checkpoint-143/rng_state.pth\n/kaggle/working/T5/checkpoint-143/model.safetensors\n/kaggle/working/T5/checkpoint-143/config.json\n/kaggle/working/T5/checkpoint-143/tokenizer_config.json\n/kaggle/working/T5/checkpoint-143/tokenizer.json\n/kaggle/working/T5/checkpoint-143/training_args.bin\n/kaggle/working/T5/checkpoint-143/generation_config.json\n/kaggle/working/T5/checkpoint-143/special_tokens_map.json\n/kaggle/working/T5/runs/Apr23_20-21-29_42234fde9499/events.out.tfevents.1713903690.42234fde9499.34.0\n/kaggle/working/T5/runs/Apr23_20-21-29_42234fde9499/events.out.tfevents.1713904032.42234fde9499.34.1\n/kaggle/working/T5/checkpoint-104/trainer_state.json\n/kaggle/working/T5/checkpoint-104/spiece.model\n/kaggle/working/T5/checkpoint-104/optimizer.pt\n/kaggle/working/T5/checkpoint-104/scheduler.pt\n/kaggle/working/T5/checkpoint-104/rng_state.pth\n/kaggle/working/T5/checkpoint-104/model.safetensors\n/kaggle/working/T5/checkpoint-104/config.json\n/kaggle/working/T5/checkpoint-104/tokenizer_config.json\n/kaggle/working/T5/checkpoint-104/tokenizer.json\n/kaggle/working/T5/checkpoint-104/training_args.bin\n/kaggle/working/T5/checkpoint-104/generation_config.json\n/kaggle/working/T5/checkpoint-104/special_tokens_map.json\n/kaggle/working/T5/checkpoint-130/trainer_state.json\n/kaggle/working/T5/checkpoint-130/spiece.model\n/kaggle/working/T5/checkpoint-130/optimizer.pt\n/kaggle/working/T5/checkpoint-130/scheduler.pt\n/kaggle/working/T5/checkpoint-130/rng_state.pth\n/kaggle/working/T5/checkpoint-130/model.safetensors\n/kaggle/working/T5/checkpoint-130/config.json\n/kaggle/working/T5/checkpoint-130/tokenizer_config.json\n/kaggle/working/T5/checkpoint-130/tokenizer.json\n/kaggle/working/T5/checkpoint-130/training_args.bin\n/kaggle/working/T5/checkpoint-130/generation_config.json\n/kaggle/working/T5/checkpoint-130/special_tokens_map.json\n/kaggle/working/T5/checkpoint-117/trainer_state.json\n/kaggle/working/T5/checkpoint-117/spiece.model\n/kaggle/working/T5/checkpoint-117/optimizer.pt\n/kaggle/working/T5/checkpoint-117/scheduler.pt\n/kaggle/working/T5/checkpoint-117/rng_state.pth\n/kaggle/working/T5/checkpoint-117/model.safetensors\n/kaggle/working/T5/checkpoint-117/config.json\n/kaggle/working/T5/checkpoint-117/tokenizer_config.json\n/kaggle/working/T5/checkpoint-117/tokenizer.json\n/kaggle/working/T5/checkpoint-117/training_args.bin\n/kaggle/working/T5/checkpoint-117/generation_config.json\n/kaggle/working/T5/checkpoint-117/special_tokens_map.json\n/kaggle/working/T5/checkpoint-156/trainer_state.json\n/kaggle/working/T5/checkpoint-156/spiece.model\n/kaggle/working/T5/checkpoint-156/optimizer.pt\n/kaggle/working/T5/checkpoint-156/scheduler.pt\n/kaggle/working/T5/checkpoint-156/rng_state.pth\n/kaggle/working/T5/checkpoint-156/model.safetensors\n/kaggle/working/T5/checkpoint-156/config.json\n/kaggle/working/T5/checkpoint-156/tokenizer_config.json\n/kaggle/working/T5/checkpoint-156/tokenizer.json\n/kaggle/working/T5/checkpoint-156/training_args.bin\n/kaggle/working/T5/checkpoint-156/generation_config.json\n/kaggle/working/T5/checkpoint-156/special_tokens_map.json\n/kaggle/working/T5_overall/spiece.model\n/kaggle/working/T5_overall/model.safetensors\n/kaggle/working/T5_overall/config.json\n/kaggle/working/T5_overall/tokenizer_config.json\n/kaggle/working/T5_overall/tokenizer.json\n/kaggle/working/T5_overall/training_args.bin\n/kaggle/working/T5_overall/generation_config.json\n/kaggle/working/T5_overall/special_tokens_map.json\n","output_type":"stream"}]}]}